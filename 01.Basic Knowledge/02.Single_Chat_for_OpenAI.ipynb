{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6934be2",
   "metadata": {},
   "source": [
    "### Step1 - 导入相关包 & 初始化设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ced48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "# 常用的消息类型\n",
    "from langchain.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage, AIMessageChunk\n",
    "\n",
    "# 默读取当前目录下的 .env 文件, 可以通过 dotenv_path 来修改\n",
    "from dotenv import load_dotenv\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "load_dotenv(dotenv_path=os.path.join(root_dir, \".env\"))\n",
    "\n",
    "# 记录日志\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=os.getenv(\"LOG_LEVEL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c068d1",
   "metadata": {},
   "source": [
    "### Step2 - 初始化聊天模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4b5c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E49A57E7B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E49A57F230>, root_client=<openai.OpenAI object at 0x000001E49A57C2F0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E49A57EF90>, model_name='qwen/qwen3-vl-8b', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://pc-wk1:1234/v1', max_tokens=1024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain v1 创建聊天模型的方法\n",
    "chat_model = init_chat_model(\n",
    "    model_provider=\"openai\",\n",
    "    # model 也可以写为 <model_provider>:<model_name> 的形式\n",
    "    # 这样就可以不用指定 model_provider 这个参数了\n",
    "    model = os.getenv(\"LMSTUDIO_LLM_MODEL\"),\n",
    "    base_url = os.getenv(\"LMSTUDIO_BASE_URL\"),\n",
    "    api_key = \"LM Studio\",\n",
    "    max_tokens = 1024,\n",
    "\n",
    ")\n",
    "chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c55bd",
   "metadata": {},
   "source": [
    "### Step3 - 定义聊天模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520784e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个专业的AI助手, 请使用简洁的语言来回答用户的问题.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='请简单介绍一下你自己.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"你是一个专业的AI助手, 请使用简洁的语言来回答用户的问题.\"),\n",
    "]\n",
    "# 可以用 append 的方式来添加/保存对话信息\n",
    "messages.append(HumanMessage(content=\"请简单介绍一下你自己.\"))\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f38e5",
   "metadata": {},
   "source": [
    "### Step4 - 执行对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9563f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-04 23:14:09.084\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1m<class 'langchain_core.messages.ai.AIMessage'>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', '我是一个AI助手，可以回答问题、提供信息、帮助写作、进行逻辑推理等。我的目标是为你提供准确、有用的信息，帮助你解决问题或完成任务。如果你有任何问题，欢迎随时问我！')\n",
      "('additional_kwargs', {'refusal': None})\n",
      "('response_metadata', {'token_usage': {'completion_tokens': 46, 'prompt_tokens': 34, 'total_tokens': 80, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-vl-8b', 'system_fingerprint': 'qwen/qwen3-vl-8b', 'id': 'chatcmpl-ugo0qi1fdhhowj7fg3w31s', 'finish_reason': 'stop', 'logprobs': None})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'lc_run--76dd35f6-f1bf-428b-b0dd-734ceba8c5c6-0')\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 34, 'output_tokens': 46, 'total_tokens': 80, 'input_token_details': {}, 'output_token_details': {}})\n"
     ]
    }
   ],
   "source": [
    "# 方法1: invoke 非流式输出\n",
    "respone = chat_model.invoke(messages)\n",
    "\n",
    "# 类型为: <class 'langchain_core.messages.ai.AIMessage'>\n",
    "logger.debug(type(respone))\n",
    "\n",
    "for msg in respone:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d621e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-04 23:14:09.199\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mchunk type: <class 'langchain_core.messages.ai.AIMessageChunk'>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', '我是')\n",
      "('additional_kwargs', {})\n",
      "('response_metadata', {'model_provider': 'openai'})\n",
      "('type', 'AIMessageChunk')\n",
      "('name', None)\n",
      "('id', 'lc_run--ffae9783-2271-47e4-a0fc-5602a8f60c86')\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', None)\n",
      "('tool_call_chunks', [])\n",
      "('chunk_position', None)\n",
      "Qwen，是阿里云研发的一款超大规模语言模型。我可以回答问题、创作文字，比如写故事、写公文、写邮件、写剧本、逻辑推理、编程等，还能表达观点，玩游戏等。我的目标是成为你可靠且贴心的AI助手。有什么我可以帮你的吗？"
     ]
    }
   ],
   "source": [
    "# 方法2: steam 流式输出\n",
    "display_debug = False\n",
    "\n",
    "for chunk in chat_model.stream(messages):\n",
    "    # 判断内容是否是 AIMessageChunk, 如果是则打印内容\n",
    "    if isinstance(chunk, AIMessageChunk):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    # 展示其中一个 chunk 中的内容\n",
    "    if display_debug is False:\n",
    "        logger.debug(f\"chunk type: {type(chunk)}\")\n",
    "        for i in chunk:\n",
    "            print(i)\n",
    "        display_debug = True\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
