{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33709af",
   "metadata": {},
   "source": [
    "### Step1 - 导入相关包 & 初始化设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecdf67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# https://reference.langchain.com/python/langchain_text_splitters/\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 默读取当前目录下的 .env 文件, 可以通过 dotenv_path 来修改\n",
    "from dotenv import load_dotenv\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "load_dotenv(dotenv_path=os.path.join(root_dir, \".env\"))\n",
    "\n",
    "# 记录日志\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=os.getenv(\"LOG_LEVEL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003923d",
   "metadata": {},
   "source": [
    "### Step2 - 加载 PDF 文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e28465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-07 14:14:50.518\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m6\u001b[0m - \u001b[34m\u001b[1m整个文档对象的类型: <class 'list'>\u001b[0m\n",
      "\u001b[32m2025-12-07 14:14:50.519\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[34m\u001b[1m每个文档对象的类型: <class 'langchain_core.documents.base.Document'>\u001b[0m\n",
      "\u001b[32m2025-12-07 14:14:50.520\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m每个文档对象元数据: {'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2017-12-07T01:03:15+00:00', 'author': '', 'keywords': '', 'moddate': '2017-12-07T01:03:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': './1706.03762v5.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\u001b[0m\n",
      "\u001b[32m2025-12-07 14:14:50.520\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1m文档总页数: 15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 利用 PyPDFLoader 实例对象来读取指定路径的 pdf 文件\n",
    "file_path = \"./Attention Is All You Need.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "logger.debug(f\"整个文档对象的类型: {type(docs)}\")\n",
    "logger.debug(f\"每个文档对象的类型: {type(docs[0])}\")\n",
    "# 文档内容为 docs[0].page_content\n",
    "logger.debug(f\"每个文档对象元数据: {docs[0].metadata}\")\n",
    "logger.debug(f\"文档总页数: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b71710",
   "metadata": {},
   "source": [
    "### Step3 - 切分文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afd7fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-07 14:14:50.529\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[34m\u001b[1m切分后每个块元数据: {'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2017-12-07T01:03:15+00:00', 'author': '', 'keywords': '', 'moddate': '2017-12-07T01:03:15+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': './1706.03762v5.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'start_index': 0}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 创建一个文本切分器, 将文档切分为块(chunk)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "# 切分指定文档\n",
    "# all_chunks 是一个列表, 每个元素是一个 Document 对象\n",
    "all_chunks = text_splitter.split_documents(docs)\n",
    "# Document 内容为 all_chunks[0].page_content\n",
    "logger.debug(f\"切分后每个块元数据: {all_chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e3783",
   "metadata": {},
   "source": [
    "### Step4 - 将切分后的文档块向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df90a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-07 14:14:53.841\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[34m\u001b[1m单个文本经过向量化后的维度: 2560\u001b[0m\n",
      "\u001b[32m2025-12-07 14:14:54.097\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[34m\u001b[1m多个文本经过向量化后的形状: (2, 2560)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 创建一个嵌入式模型, 这里使用 Ollama 嵌入模型来进行文本向量化\n",
    "embed_model = OllamaEmbeddings(\n",
    "    model=os.getenv(\"OLLAMA_EMB_MODEL\"),\n",
    "    base_url=os.getenv(\"OLLAMA_BASE_URL\"),\n",
    ")\n",
    "# 可以通过 embed_query() 方法将单个文本向量化\n",
    "# 可以通过 embed_documents() 方法将多个文本向量化\n",
    "logger.debug(f\"单个文本经过向量化后的维度: {len(embed_model.embed_query(all_chunks[0].page_content))}\")\n",
    "logger.debug(f\"多个文本经过向量化后的形状: {np.array(embed_model.embed_documents([\"doc_test1\", \"doc_test2\"])).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bb5dd",
   "metadata": {},
   "source": [
    "### Step5 - 保存向量化后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31ad45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-07 14:14:59.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1m已成功添加 52 个文档分块的记录\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 需要创建向量数据库, 这里使用 Chroma 来进行存储\n",
    "vector_db = Chroma(\n",
    "    # 集合名字\n",
    "    # 可以通过创建一个 chromadb.PersistentClient(Path) 对象, 并通过 list_collections() 方法来获得所有集合的名字\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embed_model,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    # 可选配置, 涉及如何计算相似度, Chroma 默认使用的是 L2 距离\n",
    "    # https://docs.trychroma.com/docs/collections/configure#hnsw-index-configuration\n",
    "    # https://reference.langchain.com/python/integrations/langchain_chroma/\n",
    "    # https://reference.langchain.com/python/integrations/langchain_chroma/#langchain_chroma.Chroma.as_retriever\n",
    "    collection_metadata={\"hnsw:space\": \"l2\"}\n",
    ")\n",
    "# 将切分好的文档添加到向量数据库中\n",
    "ids = vector_db.add_documents(all_chunks)\n",
    "logger.info(f\"已成功添加 {len(ids)} 个文档分块的记录\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
