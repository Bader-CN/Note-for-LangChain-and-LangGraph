{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6934be2",
   "metadata": {},
   "source": [
    "### Step1 - å¯¼å…¥ç›¸å…³åŒ… & åˆå§‹åŒ–è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ced48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "# å¸¸ç”¨çš„æ¶ˆæ¯ç±»å‹\n",
    "from langchain.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage, AIMessageChunk\n",
    "\n",
    "# é»˜è¯»å–å½“å‰ç›®å½•ä¸‹çš„ .env æ–‡ä»¶, å¯ä»¥é€šè¿‡ dotenv_path æ¥ä¿®æ”¹\n",
    "from dotenv import load_dotenv\n",
    "root_dir = os.path.dirname(os.getcwd())\n",
    "load_dotenv(dotenv_path=os.path.join(root_dir, \".env\"))\n",
    "\n",
    "# è®°å½•æ—¥å¿—\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=os.getenv(\"LOG_LEVEL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c068d1",
   "metadata": {},
   "source": [
    "### Step2 - åˆå§‹åŒ–èŠå¤©æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4b5c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='qwen3:4b-instruct', base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LangChain v1 åˆ›å»ºèŠå¤©æ¨¡å‹çš„æ–¹æ³•\n",
    "chat_model = init_chat_model(\n",
    "    model_provider=\"ollama\",\n",
    "    # model ä¹Ÿå¯ä»¥å†™ä¸º <model_provider>:<model_name> çš„å½¢å¼\n",
    "    # è¿™æ ·å°±å¯ä»¥ä¸ç”¨æŒ‡å®š model_provider è¿™ä¸ªå‚æ•°äº†\n",
    "    model = os.getenv(\"OLLAMA_LLM_MODEL\"),\n",
    "    base_url = os.getenv(\"OLLAMA_BASE_URL\"),\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c55bd",
   "metadata": {},
   "source": [
    "### Step3 - å®šä¹‰èŠå¤©æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520784e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹, è¯·ä½¿ç”¨ç®€æ´çš„è¯­è¨€æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹, è¯·ä½¿ç”¨ç®€æ´çš„è¯­è¨€æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜.\"),\n",
    "]\n",
    "# å¯ä»¥ç”¨ append çš„æ–¹å¼æ¥æ·»åŠ /ä¿å­˜å¯¹è¯ä¿¡æ¯\n",
    "messages.append(HumanMessage(content=\"è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±.\"))\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f38e5",
   "metadata": {},
   "source": [
    "### Step4 - æ‰§è¡Œå¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9563f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-04 23:05:29.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m5\u001b[0m - \u001b[34m\u001b[1m<class 'langchain_core.messages.ai.AIMessage'>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', 'ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä¸“æ³¨äºæä¾›å‡†ç¡®ã€ç®€æ´çš„ä¿¡æ¯å’Œå¸®åŠ©è§£å†³é—®é¢˜ã€‚æˆ‘å¯ä»¥å›ç­”é—®é¢˜ã€æä¾›å»ºè®®ã€ååŠ©å†™ä½œï¼Œä¹Ÿå¯ä»¥é™ªä½ èŠå¤©ã€‚æ— è®ºä½ æœ‰ä»€ä¹ˆéœ€æ±‚ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›ä¸ºä½ æœåŠ¡ï¼ğŸ˜Š')\n",
      "('additional_kwargs', {})\n",
      "('response_metadata', {'model': 'qwen3:4b-instruct', 'created_at': '2025-12-04T15:05:29.3925582Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1101230200, 'load_duration': 181060300, 'prompt_eval_count': 34, 'prompt_eval_duration': 290296100, 'eval_count': 44, 'eval_duration': 611371700, 'logprobs': None, 'model_name': 'qwen3:4b-instruct', 'model_provider': 'ollama'})\n",
      "('type', 'ai')\n",
      "('name', None)\n",
      "('id', 'lc_run--81105da1-a7b7-4cc9-b152-50c49166c6db-0')\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', {'input_tokens': 34, 'output_tokens': 44, 'total_tokens': 78})\n"
     ]
    }
   ],
   "source": [
    "# æ–¹æ³•1: invoke éæµå¼è¾“å‡º\n",
    "respone = chat_model.invoke(messages)\n",
    "\n",
    "# ç±»å‹ä¸º: <class 'langchain_core.messages.ai.AIMessage'>\n",
    "logger.debug(type(respone))\n",
    "\n",
    "for msg in respone:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d621e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-04 23:05:29.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[34m\u001b[1mchunk type: <class 'langchain_core.messages.ai.AIMessageChunk'>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', 'ä½ å¥½')\n",
      "('additional_kwargs', {})\n",
      "('response_metadata', {})\n",
      "('type', 'AIMessageChunk')\n",
      "('name', None)\n",
      "('id', 'lc_run--d5d5a59d-c74c-4958-aeb8-81b8d21f3b81')\n",
      "('tool_calls', [])\n",
      "('invalid_tool_calls', [])\n",
      "('usage_metadata', None)\n",
      "('tool_call_chunks', [])\n",
      "('chunk_position', None)\n",
      "ï¼æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œä¸“æ³¨äºæä¾›å‡†ç¡®ã€ç®€æ´çš„ä¿¡æ¯å’Œå¸®åŠ©è§£å†³å„ç§é—®é¢˜ã€‚æˆ‘å¯ä»¥å›ç­”ä½ çš„ç–‘é—®ã€æä¾›å»ºè®®ã€ååŠ©å†™ä½œæˆ–è¿›è¡Œé€»è¾‘æ¨ç†ã€‚æ— è®ºä½ æœ‰ä»€ä¹ˆéœ€æ±‚ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›ä»¥æ¸…æ™°ã€å¯é çš„æ–¹å¼å›åº”ä½ ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
     ]
    }
   ],
   "source": [
    "# æ–¹æ³•2: steam æµå¼è¾“å‡º\n",
    "display_debug = False\n",
    "\n",
    "for chunk in chat_model.stream(messages):\n",
    "    # åˆ¤æ–­å†…å®¹æ˜¯å¦æ˜¯ AIMessageChunk, å¦‚æœæ˜¯åˆ™æ‰“å°å†…å®¹\n",
    "    if isinstance(chunk, AIMessageChunk):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    # å±•ç¤ºå…¶ä¸­ä¸€ä¸ª chunk ä¸­çš„å†…å®¹\n",
    "    if display_debug is False:\n",
    "        logger.debug(f\"chunk type: {type(chunk)}\")\n",
    "        for i in chunk:\n",
    "            print(i)\n",
    "        display_debug = True\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
